Source: `nicklaf` at YCombinator

# How or where to begin learning mathematics from first principles?

I absolutely, positively second the recommendation of "Real Mathematical Analysis" by Charles Pugh (don't miss the advice he relates from his colleague, on pages 9&10, with the heading "Metaphor and Analogy", which could easily form the basis for a dissertation on the psychology of mathematical intuition and inspiration). Pugh does an exquisite, uncommonly good job of avoiding a pitfall that >99.9% of mathematics authors fall into, making it more or less impossible for one to genuinely understand mathematics outside of a university. What pedagogy is it that Pugh (and Spivak) care enough to get right, where nearly all others fail? It is this: Pugh has carefully crafted his book into what I'd call a 'mind expansion tool': almost everything there is crafted to be read, internalized, and meditated on. By contrast, almost all other mathematics books read like a laundry list of theorems and proofs, with some discussion inserted as an afterthought.

Let me tell you a dirty secret about mathematics textbooks: almost all of them are highly flawed and incomplete dialogs between the author and the supposed reader. The reason for this: the first and foremost purpose of almost all mathematics textbooks is to organize the AUTHOR'S conception of the subject (not the student's!), for the primary purpose of TEACHING a course on the subject. In other words, the book's primary purpose is NOT to be read directly. A given mathematics textbook represents a model of the way in which the author (casually) BELIEVES students of your level might try to reason about the subject, whereas in reality, the author has so long ago advanced beyond your level that s/he cannot even remember how difficult it was when s/he first learned the subject.

If you attempt to read most mathematics texts directly, outside the context of a university course (and without having already gained a true understanding of mathematics), you will almost certainly reach a stage in your reading in which you have internalized a certain amount of verbiage (say, some theorems, maybe a proof or two, and some light discussion, with the pretense that the abstractions introduced are 'useful' for some unknown reason). Certainly, you are asked to do some problems at the end of the section, and this is in fact a somewhat reliable way to reach some kind of personal discovery, and hopefully at least some mild enlightenment about just what the section was really about. (A good textbook will have highly instructive problems; however, the difficulty is, it is virtually impossible to know just how worthy of your time they will be before you spend hours working on them.)

However, even at university, I almost NEVER resorted to reading the textbook: careful attention paid to the lecture, copious notes, regular attendance of office hours, and most of all, intense thought about the problems SPECIFICALLY given (and hopefully invented) by the lecturer were all that I was ever inclined to pursue (and all that I ever needed to succeed). If I read the textbook at all, it was only ever sought as a reference, or to fill in the gaps of a lecture which I failed to understand completely. Which is precisely the reason most math texts read so poorly: they are supplementary material for university courses.

Despite vouching for it, I do not recommend you only read Pugh--at least not right away, and not from cover-to-cover. If you must start from scratch, please start with Spivak's "Calculus", which is similarly excellent in directly addressing the pedagogical needs of an autodidactical learner. Please note that by far the most thing to learn when studying mathematics is something that is impossible to encapsulate in any specific result; I am talking about "mathematical maturity". If you only do a one or two problems in all of Spivak, but spend several hours thinking deeply about a specific aspect of a problem or passage that leads you to have new, creative thoughts, you will have learned more than you could have by merely working through it in a mindless fashion.

If you do intend to make it through a significant chunk of Spivak, be prepared to spend an enormous amount of time at it. There are many, many difficult problems in it. In addition, you should be spending time and effort not only writing down the steps of your proofs, but trying to come to grips with the very definitions you are working with. In mathematics, definitions and assumptions are most important--and they are certainly more important than clever tricks. This is why graduate students in mathematics have to learn their subjects over again--most undergraduate subjects do not do a precise or complete enough job of completely stating all definitions needed to make the theory entirely clear.

The greatest mathematician of the 20th century, Alexander Grothendieck (who recently passed away), was as productive as he was because of his uncanny skill in inventing definitions of mathematical objects which put the problem in a broader context. Raw mathematical power is available to mathematicians to the extent that they allow the context of ANY given problem which they attempt to expand in their mind, until it connects with the relevant intuition. Once this inspiration strikes, the answer becomes easy. To Grothendieck, solving a problem was more a test of his ability to create a useful theory, than an end to itself. This speaks volumes to the value of thinking abstractly and creatively, rather than just trying out hoards of problems and expecting things to magically line up in your brain, hoping for an answer to pop out. There are generally two kinds of problems in mathematics: those which simply require organizing the essential definitions and required theorems until the answer is obvious, and those which need a fundamentally new idea. In neither case will you be able to 'plug and chug'. A great deal of harm is done to students of mathematics in grade school, because the subjects are invariably taught by non-mathematicians, in a highly non-mathematical way--in fact, in a way that is antithetical to the very core of the subject. Please google and read Paul Lockhart's essay titled "A Mathematician's Lament" to see if you really understand just what mathematics is (or if deleterious notions from your schooldays are continuing to blind you from the simple beauty of pure mathematics). I will add as well the recommendation that you read G.H. Hardy's essay, "A Mathematician's Apology".

Learning mathematics is so incredibly difficult for the novice because it is almost impossible to teach this process. One must fail over and over again. I cannot lie: mathematics will be probably be difficult and unnatural for everybody except those who allow themselves enough time to commit to thinking freely and creatively about it, until a point of 'accelerating returns' is reached. Attempting to proceed directly to applied problems will invariably fail. The counter-intuitive truth about applied mathematics is that studying pure mathematics is in fact far more practical than attempting to think about the problem directly. This is because an understanding of pure mathematics gives you the ability to CREATE. Alfred Whitehead said: "'Necessity is the mother of invention' is a silly proverb. 'Necessity is the mother of futile dodges' is much nearer the truth."

I'll also leave you with a relevant quote from the great expository writer and mathematician Paul Halmos: "What does it take to be [a mathematician]? I think I know the answer: you have to be born right, you must continually strive to become perfect, you must love mathematics more than anything else, you must work at it hard and without stop, and you must never give up."

And another, in which he tells you how you should read a mathematics text: "Don't just read it; fight it! Ask your own questions, look for your own examples, discover your own proofs. Is the hypothesis necessary? Is the converse true? What happens in the classical special case? What about the degenerate cases? Where does the proof use the hypothesis?"

I have heard professional mathematicians express themselves the difficulty that even they have in maintaining the attention span required to read a traditionally written, unmotivated mathematics textbook. One such mathematician said that he skipped directly to the theorems, and attempted to discover a proof for himself. This is another secret to mathematics: it is always better to invent proofs yourself than to read the ones given in the text. This may be counter-productive in the early stages of your learning, but it is something you should continuously challenge yourself to attempt. If the first steps of a proof do not come to mind automatically, cover up the proof given in the text, except for the first few words. Then try to prove it again from scratch, with the knowledge that the objects being used in just that initial part might be part of one possible proof. Repeat as necessary, until you have either discovered a proof for yourself, or you have uncovered the entire proof given in the text. In either case, you will have thought long and hard enough to never forget the definitions and ideas needed to write the proof you end up with, even if you forget the proof itself. Later, you will only remember the essential idea. Then, it is an excellent exercise to attempt to work out the details again.

# Question: Will it help people in other domains like electronics?

Well, if you really take to heart what Spivak and Pugh have to say (and are thinking hard about the problems), there is a very good chance that you will be inspired enough to do further research that will lead you to tangentially related mathematics. So, in all likelihood, you will start to branch out even before you manage to finish your first serious math book. (Taking this to the extreme, Paul Halmos once pointed out that a good way to learn a great deal of mathematics is to read the first chapter of many different books.)
It's certainly not the case that Spivak and Pugh are the only books out there which help you develop the "mathematical maturity" that will allow you to apply mathematics creatively in other areas. For a mathematics major in college, real analysis probably is the optimum choice of subject. (Not every mathematician directly needs real analysis, but almost all would undoubtedly say that the subject shaped his or her thinking, even if only to provide a setting to learn about writing rigorous proofs.)

That said, for someone who doesn't intend study a great deal of 'traditional', mathematics, but perhaps wants to learn about computer science and applications of mathematics to engineering problems, there certainly are more direct ways to spend the time it would take to read all of Spivak or Pugh. While learning real analysis is a great foundation for subjects that involve calculus or topology (for example, convex geometry, which has applications in optimization), there are other options too. Two subjects which are also good at introducing mathematical thinking, while at the same time being essential in many computer applications, are linear algebra and number theory. One specific number theory text doesn't come to mind. Linear algebra texts vary in emphasis. I can vouch for "Linear Algebra Done Right" by Axler, but there are many others which more heavily emphasize the applications (and there are many, many applications of linear algebra).

I am sure that there are websites (or courses, or maybe even published books) designed to introduce proof-writing in these subjects, but also also including material on using computer algebra packages (such as SAGE) to compute certain results as well.

Finally, the subject known as "discrete mathematics", as well as computer science material on the analysis of algorithms also have a great deal of connections with pure mathematics (and especially real and complex analysis, as well as basic calculus). "Concrete Mathematics" by Graham, Knuth, and Patashnik comes immediately to mind. In fact, one might say that "Concrete Mathematics" is to students of mathematics who favor discrete problems (i.e., computer science) as Spivak is to students of mathematics who favor continuous problems (i.e., traditional mathematics).

Addendum:

I should probably mention one thing. In your post, you mentioned electronics, which does not so much require an understanding of mathematics, but rather a competence in solving differential equations in physics. If you are only interested in topics that are under the umbrella of electrical engineering, then you do not need to study mathematics at all. Rather, you should be studying physics, which, except at the highest theoretical levels, is more or less the practice of solving differential equations (without the kind of abstract proofs that would satisfy a mathematician). Pure mathematics is only about proofs, but with the assurance that this understanding will allow you to apply whatever problem solving techniques you may have to new domains (including situations where it is far from obvious that they apply--this is the value of mathematics).

In short, I would say that computer science is a good segue from pure mathematics, but if your goals is electronics, the kind of thinking you will need comes from learning physics--no more, no less. On the other hand, to truly understand cryptography, a background in pure mathematics is required (specifically, you should understand number theory and abstract algebra).

One thing to keep in mind: do not be mislead by similar notation between mathematics and physics: they are very, very different subjects. Certainly, physics uses equations; in addition, many theoretical results in mathematics explain (at a very high level) why certain problem solving techniques work in physics. However (at least until you reach research level physics), the overlap ends there, with the exception of linear algebra.

In fact, if there was one subject I could recommend to you (besides basic calculus) which is pretty much universally used, from optimization, to physics (all branches), to machine learning and statistics, it would be linear algebra, no contest. (I should admit here that I've contradicted my early remark in the first paragraph that one needn't study mathematics at all to understand physics, since linear algebra and calculus are indeed mathematics. However, while learning these two subjects rigorously in the spirit of mathematics will certainly aid you conceptually when you attempt to apply them to physics, it is also true that in physics you do not need to know how to prove the results in order to use them.)

# Question: How about a statistics student?

As for statistics, I have to admit that this subject is something of a blind-spot for me. This is in part because the subject of statistics, per se, is actually a separate discipline from pure mathematics. For example, at many academic institutions, the statistics department will be on a separate floor from the math department, if it is in the same building. Statistics courses at these universities don't necessarily require a background beyond calculus; furthermore, it is often the applications to the social sciences, psychology, and business which motivate the subject matter (or, at the very least, justify funding for the department).

For these reasons, it can be often difficult to find theoretical treatments of statistics from a purely mathematical perspective. Of course, this is not inherent in the subject, and Gauss, one of the greatest pure mathematicians of all time, did groundbreaking theoretical work in the subject (e.g., the method of least squares, the "Gaussian" distribution). That said, Gauss was also an applied mathematician, and I would hazard a guess that he was driven to invent these things in the course of empirical studies (such as his work in astronomy, in which he determined the orbit of Ceres).

What approach you might want to take to studying statistics depends on your background. Since most of my background is in pure math, I actually don't have a whole lot of experience myself. Somebody who desired to study statistics from the perspective of a pure mathematician would probably need to first become solidly grounded in probability. This requires a background in real analysis, and then measure theory. If you don't already know your real analysis, then you still have a very large hump to pass over before being able to even understand what measure theory is all about.

Of course, you don't need a measure-theoretic background to understand and use statistics. In fact, I don't even know if you'd need (or want) that to study statistics from the point of view of a pure mathematician. It just happens that almost all pure mathematicians treat the subject of probability using the foundation of measure theory, and a mathematician would probably want to understand probability first before statistics.

That said, although I have not tried to read it, the book titled "All of Statistics: A Concise Course in Statistical Inference", by Wasserman, looks to me like a fast-track to clearly understanding statistics from a mathematical perspective, if there ever was one. I'd still recommend having some background in combinatorics, proofs, and some basic real analysis before attempting it. You might want to look at the prerequisites.

If you don't have a pure mathematics background, or aren't inclined to pursue one, you should just do what 99% of all basic users of statistics do: turn to an expert in the field you wish to apply the subject who has written a book on USING statistics. The book will probably be a hybrid of a crash course in statistics and a tutorial of how to use it. You'll want to learn how to use the program "R". In fact, since statistics is foremost an applied subject, this is probably the best approach anyway. For example, most of what I know about statistics (which isn't a whole lot) comes from learning about the parts I needed to do basic error analysis for undergraduate physics labs. Experimental physicists have their own books that cover the parts of statistics they use, and I imagine that it would be the same for most other subjects. You could probably learn a whole lot about statistics if you were to pursue, for example, machine learning.

One part of pure math that you should learn no matter what is the "method of least least squares". This is an easy application of linear algebra, is often in linear algebra textbooks, and is probably the most (over)used tool of statistics.

Finally, if you do want to learn more about probability first, I would recommend the books of Robert Ash. He has one on non-measure theoretic probability, called "Basic Probability Theory". It's available on his homepage, or as an inexpensive Dover paperback. Perhaps you could try all three approaches simultaneously (read the Ash book to learn about probability, the Wasserman book to try to learn some mathematical statistics (if you are so inclined, although I should warn you that it presupposes a background in undergraduate mathematics, and is somewhat expensive), as well as some third book, which goes straight to the statistics in the area you wish to apply it).

Let me put the disclaimer on all this that I have not attempted to carry out any of the recommendations here, so, unlike my previous posts, this is mostly speculative. It could be that your best bet to learning the subject is to find somebody who knows the subject and ask him / her instead!

# What is difference the between Physics and Math?

The difference is the emphasis: mathematicians focus on proofs, and therefore have to write proofs of theorems that ensure their validity in all cases. Many of these cases are what physicists would call "pathological", and so they basically ignore them when introducing calculus as a tool for students of physics. If you read the table of contents of virtually any book that professes to introduce the "mathematical methods of physics", you will see how different the emphasis is. Since the physicist doesn't care about proofs that involve concepts beyond basic plane geometry and high school algebra, s/he spends a bunch of time introducing a large number of techniques that use no more than algebraic manipulation and limits. You'll find a laundry list of topics, including: tricks of differentiation and integration, the basics of vectors and multivariate calculus (more or less in order to introduce Maxwell's equations), specific examples of Taylor expansions and infinite series (in order to provide asymptotic approximations of functions--usually solutions to differential equations which represent the physics problem you are seeking to solve--which otherwise are unwieldy or impossible to carry out algebraically), some concepts and formulas from "complex variables" (which is a very deep and beautiful subject when studied more systematically, but is also so useful to physicists because of its connection to infinite series, and hence to differential equations), and "special" functions (which may be thought of as important classes of series solutions to differential equation), and most importantly, a little bit of linear algebra theory, which more or less places the majority of these computational tools in a unified framework. (Later on, physicists make use of the an analog of linear algebra, attempting to carry out similar computations in "infinite dimensional" spaces (Hilbert spaces instead of vector spaces), in a subject that mathematicians call functional analysis. Understanding the computational parts of functional analysis is essential for physicists who desire to take their knowledge of problem solving from the domains of mechanics and E&M, and apply them to problems in quantum mechanics, which is founded on functional analysis, and is in large part responsible for the extent to which the subject itself was developed).
The reason the physicist is able to succeed in so completely developing these tools (without even proving any of them) is because s/he is constantly testing their efficacy by trying them out of physics problems. The life of a physics student is more or less an endless game of trying difficult problems, and then invariably ending up resorting to finding approximations in almost all cases.

You might say, then, that where the mathematician spends his or her time looking for watertight proofs of pure concepts about space, logic, and number, from first principles, the physicist spends an equal amount of time thinking about how to approximate differential equations. It's not too surprising that, while in theory there is a great deal of overlap, in practice, the styles of thinking are very different. Part of this is because mathematics is such a vast subject, with more branches than one can care to count, whereas the number of branches used by physicists can more or less be counted on one hand.

In order to go back to a time when mathematics and physics had not yet diverged, you probably have to return to the days of Euler, or even Newton. If you read William Dunham's excellent book, "The Calculus Gallery", in the very first chapter, you will find a discussion of Newton's very basic work on binomial series--something that physicists use almost every day. However, as that book progresses (it goes in chronological order), once you get to Cauchy, who worked in the early 19th century, you begin to see mathematicians turn their focus to questions that no longer address computational questions that could possibly find direct use by physicists, but instead are more or less exist only in the minds of mathematicians.

There certainly is a branch of real analysis, called "classical analysis", which tends to focus more on concrete examples of infinite series, which of course have roots in basic calculus and physics. You can in fact prove a great deal of interesting things about specific infinite series, but you will not invent algebraic geometry or abstract algebra, or be able to fully appreciate the scope of modern 20th century mathematics, if you confine yourself to studying the properties of just one concrete object. If you do, though, you will eventually find yourself studying complex analysis. Somebody who takes this route--that is, to reject the abstract flavor of 20th mathematics--can learn a great deal about mathematics that also happens to be very useful to physicists. On the other hand, you would be missing out on a great deal of fascinating connections between the abstract mathematics of the 20th century, and applications to problems in computer science.

On the other hand, if you really want to study pure mathematics, using proofs, you'll have to be somewhat patient before you can see applications to physics. These applications will come sporatically. Right away, linear algebra is an example of a very basic pure mathematics subject which is absolutely essential to physics. At about the same level is calculus and infinite series. Then, in mechanics, you will probably encounter what physicists call "analytical mechanics", which is an application of a pure mathematics subject called the "calculus of variations". Your understanding of this subject doesn't have to be very deep to start using it in physics, though. At a slightly higher level is complex analysis, which vastly improves your understanding of infinite series. The next application I can think of is quite a bit more advanced; it concerns general relativity, and could be thought of as an advanced setting for multivariable calculus, but which is inspired by the beauty of Euclidian geometry. I am talking about what used to be called "advanced calculus", but now has many different names. The key object of study is what is called a "manifold". A mathematician would call the subject "differential geometry", whereas a physicist would emphasize the use of objects called tensors. At this point, you will begin to see non-trivial mathematics being used in physics, but with the annoyance that physicists continue to rely on computations rather than complete proofs.

Interestingly enough, Michael Spivak, the author of the classic pure mathematics book "Calculus" (mentioned in this thread, by myself and others), is in fact somebody with an interest in mechanics, and happens to be one of the key expositors of differential geometry (see his 5-volume treatise on the subject). To this effect, he has also written an introductory book on mechanics (and is in the process of writing a sequel on the subject of E&M), but with an emphasis and style unlike any mechanics book written for physicists. The book is called "Physics for Mathematicians: Mechanics". It looks deceptively simple in terms of the amount of formula used; however, it will really only be appreciated by mathematicians who have studied some amount of differential geometry (I believe he says in the preface that it would be idea for the read to have read some subset of his 5-volume treatise on the subject). Back in the 60s, Spivak also wrote what, for years, seems to have been definitive text on multivariable analysis and differential geometry for pure mathematicians, in a book called "Calculus on Manifolds". This book is quite difficult to read, though, and today, there are more friendly introductions that presuppose less mathematical maturity, and are less terse (although the book is still a classic).

I'd like to mention one more thing, which is very important to keep in mind when studying pure mathematics: if you feel like you don't quite understand something, do NOT, under any circumstance, "pressure" or force yourself into believing it. While the saying "practice makes perfect" is perfectly applicable to computation, you have to be very careful when studying pure mathematics to fight the instinct to try and convince yourself that you understand something. It is perfectly okay not to understand something. The chances are, your best shot at understanding something that makes you uneasy is to simply admit your present situation doesn't yield any direct lines of attack toward a better understanding, and to tuck the problem in the back of your mind, until a later time, when further study (possibly in an unrelated area) unexpectedly leads you to the missing piece. You also have to be on guard against allowing trying to form an intuitive understanding of something, before you've fully understood how the idea follows from the definitions and proofs alone. Forming an intuitive understanding of ideas in mathematics is always about understanding the connections between abstract ideas, but the abstract ideas themselves should have no intuitive basis when considered by themselves. For very simple things, it is probably okay to rely on intuition in a pinch (e.g., you can safely think of the derivative of a function at a point as the slope of the line tangent to the graph of the function at the point).

To use a crude analogy, you could think of mathematics as one giant puzzle, but with the pieces coming in slowly, one at a time. Any two pieces have a fairly small chance of fitting together, but since you only have the ability to focus on one or two pieces, you need the memory of old puzzle pieces which previously did not fit anywhere in the back of your mind, so that when you do stumble upon the fitting piece, you can go back to it.

Another thing to keep in mind is that the best truths in mathematics are the most general. Every time you consider a specific example, you should always have some amount of innate desire to see a more all-encompassing idea which handles the details of the specific example as a special case. It will usually not be possible for you to come up with the right generalizations yourself, though; mathematics has evolved gradually over the last couple millennia, and it has taken the trial and error of many brilliant people before the "right" abstractions were found. Your best hope is that your teacher (or author) is leading you on a path that will eventually allow you to see how the things you've come to accept as true can be thought of as existing within a broader framework. The fact that applied mathematics books generally do not do this at all is the reason why one cannot simply try to learn about a topic in applied mathematics, and then try to learn the pure setting as an afterthought. If you go straight to the applications and computations, the chances are that you will be leaving out the conceptual legwork that will be needed to understand the subject in a way that can allow you to potentially create new theory.

To take the puzzle analogy further (to the point of breaking it), you can try to view the generalizations as pieces that connect to MANY puzzle pieces simultaneously (which is obviously not how an actual puzzle works, since each piece only connects to adjacent pieces). As you progress in mathematics, you start to see that the subject is composed of a sort of hidden hierarchy, in which you later learn that your past findings are subsumed by more general theories. Without this, the subject would be unwieldy, since no normal human is capable of committing to memory a perfectly interlocking body of thought that is only made of mostly isolated ideas. Inevitably, you will need some governing ideas, which form the root of a sort of conceptual hierarchy. However, this conceptual hierarchy is more or less impossible to convey pedagogically (c.f. all the complaints about "New Math" back in the 60s), without first understanding all the pieces involved.

(For reasons discussed in the above paragraph, you should be prepared to accumulate a very large number of books and documents, should you begin to more broadly become interested in mathematics).

One way to increase the probability that you'll find interlocking pieces in the same span of attention is to be guided by an excellent teacher (and in some cases, an excellent author). Otherwise, your best shot at exploring the space of possible directions to take is to follow this advice of Paul Halmos: "A good stack of examples, as large as possible, is indispensable for a thorough understanding of any concept, and when I want to learn something new, I make it my first job to build one."

All that said, it is true that any successful student of mathematics will eventually reach a point in his or her studies in which the writing of proofs has become natural enough that, when given a theorem that has a straightforward proof, it the student will probably be able to find it 80% of the time without too much stress or outside help. Getting to that point is important; therefore, a significant chunk of the value of studying a book like Spivak's or Pugh's is to increase your ability to write proofs. This will be a gradual process, so don't be too discouraged when you get frustrated. If you feel like you need to improve your proof writing skills, though, it would certainly help to take a break from the analysis text, and read an elementary book on proofs (just search Amazon or a university library) until you feel like you've done a good job of building up this skill. The ability to write proofs with ease is as important in pure mathematics as algebraic manipulations is important in applied mathematics.

One last warning. If you truly become skilled at pure mathematics, be aware that it can be addictive. Research mathematicians spend their entire lives on this stuff, and are most often quite happy to give up a great deal of things which non-mathematicians value (e.g., a career in industry).

Of course, this really depends on how addictive a personality you have, or if you are unfortunate enough to be a creative genius.

# Shouldn't engineers be reading books like "Vector Calculus, Linear Algebra, and Differential Forms" by Hubbard & Hubbard to get the bigger picture?

Hubbard & Hubbard is a fantastic book; for the right audience, it may be all that is needed. I'd say that every mathematically minded engineer or physicist certainly should have it. It does a fantastic job of exposing the fundamental ideas of linear algebra and multivariable calculus--and in a way that doesn't require really any prerequisites beyond basic calculus. Reading this book is like being in a lecture with an experienced practitioner of both pure and applied mathematics simultaneously (well, this is actually true of Hubbard, but most texts are not written in a way that the author is so detailed and clear so as to seem present); the notes in the margins and the extensive, direct, and clear explanations are absolutely lovely.
That said, somebody interested in building a foundation for pure mathematics, and not so much motivated by the ability to solve problems outside of mathematics, would probably be better served by reading a standard text on real analysis.

On the other hand, I myself have turned to the notes in the margins of Hubbard & Hubbard, even when studying real analysis from the purest point-of-view, because the little tidbits are just so insightful.

Somebody who really took Hubbard & Hubbard seriously, though, could come away with a monster understanding of applied mathematics, while still having learned the craft in a way that is correct enough to lead to further study in pure mathematics as well. Nobody can really go wrong having this book on his or her shelf (although it is a bit expensive).
